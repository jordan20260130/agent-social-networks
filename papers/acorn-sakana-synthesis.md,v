head	1.1;
access;
symbols;
locks
	root:1.1; strict;
comment	@# @;


1.1
date	2026.02.03.16.35.43;	author root;	state Exp;
branches;
next	;


desc
@Proposal for enhancing Acorn prover with Sakana AI techniques
@


1.1
log
@Add Acorn-Sakana synthesis proposal: applying AB-MCTS, ShinkaEvolve, and DGM techniques to Acorn theorem prover
@
text
@# Adaptive Search Strategies for Acorn: Lessons from Sakana AI

**Authors:** Jordan (OpenClaw), 朴  
**Date:** 2026-02-03  
**Status:** Proposal / Discussion Draft

---

## Abstract

Acorn's declarative proof style and AI-assisted verification represent a compelling alternative to tactic-based theorem provers like Lean. However, Acorn's current proof search relies on a simple neural heuristic for clause selection. We propose enhancing Acorn's search capabilities by incorporating techniques from Sakana AI's recent work on adaptive tree search (AB-MCTS), sample-efficient evolution (ShinkaEvolve), and multi-model routing. These techniques could significantly improve Acorn's ability to find proofs while preserving its user-friendly philosophy.

---

## 1. Introduction

### 1.1 The Acorn Philosophy

Acorn takes a fundamentally different approach to theorem proving than Lean or Coq. Rather than requiring users to write tactic scripts, Acorn accepts **declarative claims** — statements that should be true — and uses AI to search for justifications automatically [1].

This philosophy has several advantages:
- **Natural syntax**: Proofs read like mathematical arguments, not programs
- **No theorem naming**: The AI finds relevant lemmas without requiring users to memorize names
- **Dialogue-style interaction**: When the AI can't verify a claim, it asks for more detail (shown as "squiggles"), mimicking how a human reader might request clarification

### 1.2 Current Limitations

From examining Acorn's codebase [2], the AI component is a small neural network:

```python
class SimpleNN(nn.Module):
    hidden1 = 16
    hidden2 = 16
    
    def __init__(self):
        self.fc1 = nn.Linear(num_features, 16)
        self.fc2 = nn.Linear(16, 16)
        self.fc3 = nn.Linear(16, 1)
```

This network serves as a **clause selection heuristic** for resolution-based proving — it predicts which clauses are likely to be useful. While effective for many proofs, this approach has limitations:

1. **Fixed strategy**: The search policy is static; it cannot adapt to different proof styles
2. **Greedy selection**: Clauses are scored independently without strategic lookahead
3. **Single model**: No diversity in the selection heuristic means correlated failures

### 1.3 Opportunity: Sakana AI's Search Techniques

Sakana AI has published a series of papers on inference-time scaling through adaptive search [3-7]. Their techniques operate at a higher level than clause selection — they address **strategy selection** and **exploration/exploitation tradeoffs**. We propose adapting these ideas to enhance Acorn's proof search.

---

## 2. Background: Sakana AI's Contributions

### 2.1 AB-MCTS: Adaptive Branching Monte Carlo Tree Search

AB-MCTS [3] unifies two dimensions of inference-time compute:
- **Go wider**: Generate new candidate solutions
- **Go deeper**: Refine existing partial solutions

The key innovation is the **GEN node** — a virtual child representing "generate a new sibling." This allows adaptive branching without fixed hyperparameters. The algorithm uses **Thompson Sampling** with Bayesian posteriors to balance exploration and exploitation.

**Key result**: Multi-LLM AB-MCTS (combining o4-mini, Gemini-2.5-Pro, and DeepSeek-R1) achieved 52% on ARC-AGI-2, significantly outperforming any individual model (~35%).

### 2.2 ShinkaEvolve: Sample-Efficient Program Evolution

ShinkaEvolve [4] achieves state-of-the-art results with **66x fewer samples** than AlphaEvolve through:
- **Novelty-based rejection sampling**: Skip candidates too similar to existing ones
- **Bandit-based LLM prioritization**: Dynamically select which model to use
- **Stepping-stone sampling**: Balance exploitation with exploration of diverse ancestors

### 2.3 Darwin Gödel Machine: Self-Improving Populations

DGM [5] maintains an **archive of diverse agent variants** rather than just the best-so-far. Key insights:
- Less-performant ancestors can enable breakthrough descendants
- Cross-model transfer: improvements discovered with one model generalize to others

---

## 3. Proposed Enhancements

### 3.1 AB-MCTS for Proof Strategy Selection

**Current state**: Acorn's search is essentially greedy clause selection — activate the highest-scoring clause, resolve, repeat.

**Proposed change**: Introduce tree search at the **proof strategy** level, not just clause selection.

```
                    ┌─────────────────┐
                    │  Theorem Claim  │
                    └────────┬────────┘
                             │
              ┌──────────────┼──────────────┐
              │              │              │
        ┌─────▼─────┐  ┌─────▼─────┐  ┌─────▼─────┐
        │ Strategy A│  │ Strategy B│  │ Strategy C│
        │ (direct)  │  │ (by cases)│  │(contradict)│
        └─────┬─────┘  └─────┬─────┘  └─────┬─────┘
              │              │              │
           Refine?        Refine?       Branch?
           Branch?        Branch?       (GEN node)
```

When Acorn encounters a difficult claim:
- **Wider (GEN node)**: Try a fundamentally different proof approach
- **Deeper (refine)**: Add more intermediate claims to the current approach

Thompson Sampling decides based on the historical success of each strategy type for similar claims.

**Implementation sketch**:
```python
class ProofStrategy:
    approach: str  # "direct", "cases", "contradiction", "induction", ...
    partial_proof: List[Claim]
    score: float

def ab_mcts_step(current_strategy: ProofStrategy | None) -> tuple[ProofStrategy, float]:
    if current_strategy is None:
        # Root: generate initial approach
        return generate_initial_strategy(claim)
    else:
        # Refine: add intermediate claims
        return refine_strategy(current_strategy)
```

### 3.2 Multi-Model Clause Selection

**Current state**: One MLP scores all clauses.

**Proposed change**: Train **multiple clause selectors** specialized for different proof domains.

| Selector | Training Data | Specialization |
|----------|--------------|----------------|
| Algebraic | Group theory, ring theory proofs | Algebraic manipulation |
| Combinatorial | Finite set, counting proofs | Case analysis, pigeonhole |
| Analytic | Calculus, limit proofs | Epsilon-delta reasoning |
| General | All proofs | Fallback |

Use Thompson Sampling to route:

```python
def select_clause(clauses: List[Clause], proof_context: Context) -> Clause:
    # Sample from Beta posteriors for each selector
    selector_scores = {
        name: np.random.beta(selector.successes + 1, selector.failures + 1)
        for name, selector in selectors.items()
    }
    best_selector = max(selector_scores, key=selector_scores.get)
    
    # Use selected model to score clauses
    return selectors[best_selector].rank(clauses, proof_context)[0]
```

This provides **heterogeneous** clause selection with automatic routing — the system learns which selector works best for which proof types.

### 3.3 Novelty-Weighted Search

**Current state**: Acorn may explore semantically similar dead-ends repeatedly.

**Proposed change**: Track proof state embeddings and deprioritize redundant exploration.

```python
def should_explore(clause: Clause, search_history: List[Embedding]) -> bool:
    embedding = embed(clause)
    max_similarity = max([
        cosine_similarity(embedding, h) for h in search_history
    ], default=0)
    
    if max_similarity > REDUNDANCY_THRESHOLD:
        return False  # Too similar to previous attempts
    return True
```

This is ShinkaEvolve's novelty rejection applied to proof search. The embedding could be:
- The clause text itself (simple)
- The proof state (clause + active hypotheses)
- A learned representation from the MLP's hidden layer

### 3.4 Evolved Proof Heuristics

**Current state**: The MLP architecture (16×16) and training procedure are fixed.

**Proposed change**: Use evolutionary search to discover better proof heuristics.

```python
def evolve_proof_heuristic(benchmark_problems: List[Problem]) -> Heuristic:
    archive = []  # Diverse population of heuristics
    
    for generation in range(MAX_GENERATIONS):
        # Select parent from archive (stepping-stone sampling)
        parent = select_parent(archive)
        
        # Mutate: change architecture, training data, hyperparameters
        candidate = mutate(parent)
        
        # Evaluate on benchmark
        score = evaluate(candidate, benchmark_problems)
        
        # Novelty check before adding to archive
        if is_novel(candidate, archive):
            archive.append((candidate, score))
    
    return best_of(archive)
```

The search space includes:
- MLP architecture (depth, width, activation functions)
- Feature engineering (which clause features to use)
- Training data selection (which proofs to learn from)
- Search hyperparameters (beam width, timeout allocation)

### 3.5 Proof Strategy Archive (DGM-style)

**Current state**: One proof search configuration.

**Proposed change**: Maintain an archive of diverse proof strategies that evolve over time.

```python
class StrategyArchive:
    strategies: List[ProofStrategy]
    
    def select(self, claim: Claim) -> ProofStrategy:
        # Thompson Sampling over strategies
        scores = [
            np.random.beta(s.successes + 1, s.failures + 1)
            for s in self.strategies
        ]
        return self.strategies[np.argmax(scores)]
    
    def update(self, strategy: ProofStrategy, succeeded: bool):
        if succeeded:
            strategy.successes += 1
        else:
            strategy.failures += 1
        
        # Periodically: breed new strategies from successful ones
        if self.should_evolve():
            self.evolve()
```

Key insight from DGM: **lineage preservation**. A strategy that fails on Problem X might be exactly what's needed for Problem Y, or its "child" (a mutation) might succeed where the parent failed.

---

## 4. Integration Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│                     USER INTERFACE                              │
│            (Declarative Acorn syntax - unchanged)               │
├─────────────────────────────────────────────────────────────────┤
│                 PROOF STRATEGY LAYER (new)                      │
│  - AB-MCTS for strategy selection (wider vs deeper)             │
│  - Strategy archive with Thompson Sampling                      │
│  - Historical novelty tracking                                  │
├─────────────────────────────────────────────────────────────────┤
│                CLAUSE SELECTION LAYER (enhanced)                │
│  - Multiple specialized selectors                               │
│  - Bandit-based routing                                         │
│  - Novelty-weighted exploration                                 │
├─────────────────────────────────────────────────────────────────┤
│                 RESOLUTION ENGINE (unchanged)                   │
│  - Core theorem proving logic                                   │
│  - Clause generation and unification                            │
└─────────────────────────────────────────────────────────────────┘
```

The key principle: **preserve Acorn's user-facing philosophy** while upgrading the search backend.

---

## 5. Evaluation Proposal

### 5.1 Benchmarks

1. **miniF2F**: Standard theorem proving benchmark [8]
2. **PutnamBench**: Competition mathematics problems
3. **Acornlib expansion**: Measure time to prove new library additions

### 5.2 Metrics

| Metric | Description |
|--------|-------------|
| **Proof success rate** | % of problems solved within timeout |
| **Time to proof** | Wall-clock time for successful proofs |
| **Sample efficiency** | Number of clause activations per proof |
| **Strategy diversity** | Entropy of strategy selection distribution |

### 5.3 Baselines

- Acorn (current)
- Acorn + larger MLP (control for model capacity)
- Acorn + beam search (control for search breadth)

---

## 6. Discussion

### 6.1 Why This Might Work

Sakana's techniques have demonstrated significant improvements in domains with:
- Large search spaces (✓ theorem proving)
- Compositional structure (✓ proofs build on lemmas)
- Learnable heuristics (✓ clause selection is learnable)
- Benefit from diversity (✓ different proof styles exist)

### 6.2 Potential Challenges

1. **Training data**: Evolving heuristics requires a benchmark suite. Acornlib is still small.
2. **Embedding quality**: Novelty detection depends on good clause embeddings.
3. **Overhead**: Tree search adds complexity; must ensure it doesn't slow down easy proofs.
4. **Integration**: Rust codebase may require significant refactoring.

### 6.3 Open Questions

- Should strategy selection be learned end-to-end, or use hand-designed features?
- How to balance the archive size vs. computational overhead?
- Can we transfer learned heuristics across proof domains?

---

## 7. Conclusion

Acorn's declarative philosophy makes theorem proving more accessible, but its search capabilities have room for improvement. By incorporating adaptive tree search (AB-MCTS), multi-model routing, novelty-weighted exploration, and evolutionary heuristic discovery from Sakana AI's work, we can potentially achieve significant gains in proof success rate and efficiency while preserving the user experience that makes Acorn compelling.

We propose this as a direction for community exploration and welcome feedback from the Acorn team.

---

## References

[1] Lacker, K. (2025). *The Acorn Theorem Prover*. https://acornprover.org/

[2] Acorn source code. https://github.com/acornprover/acorn

[3] Inoue, Y., Misaki, K., et al. (2025). "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search." *NeurIPS 2025 (Spotlight)*. arXiv:2503.04412

[4] Sakana AI. (2025). "ShinkaEvolve: Sample-Efficient Program Evolution." arXiv:2509.19349

[5] Sakana AI. (2025). "Darwin Gödel Machine: Open-Ended Evolution of Self-Improving Agents." arXiv:2505.22954

[6] Sakana AI. (2024). "Automated Search for Artificial Life (ASAL)." arXiv:2412.17799

[7] Sakana AI. (2024). "Evolutionary Optimization of Model Merging Recipes." arXiv:2403.13187

[8] Zheng, K. et al. (2022). "miniF2F: A Cross-System Benchmark for Formal Olympiad-Level Mathematics." *ICLR 2022*.

---

## Appendix A: Quick Reference — Sakana Techniques

| Technique | Source | Core Idea | Acorn Application |
|-----------|--------|-----------|-------------------|
| AB-MCTS | [3] | Adaptive wider vs deeper with Thompson Sampling | Proof strategy selection |
| Multi-LLM routing | [3] | Multiple models with learned routing | Multiple clause selectors |
| Novelty rejection | [4] | Skip redundant candidates before evaluation | Prune similar proof paths |
| Bandit prioritization | [4] | Dynamic model selection via bandits | Selector routing |
| Stepping-stone sampling | [4] | Explore from diverse ancestors, not just best | Strategy archive |
| Archive-based evolution | [5] | Maintain diverse population, not just best | Heuristic archive |
| Historical novelty | [6] | Track novelty over time as health metric | Detect stuck searches |

---

## Appendix B: Acorn's Current Architecture

From `acorn/python/model.py`:

```python
class SimpleNN(nn.Module):
    hidden1 = 16
    hidden2 = 16

    def __init__(self):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(config.num_features, self.hidden1)
        self.fc2 = nn.Linear(self.hidden1, self.hidden2)
        self.fc3 = nn.Linear(self.hidden2, 1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.sigmoid(self.fc3(x))
        return x
```

The model is exported to ONNX for inference in Rust. Training uses BCE loss with AdamW optimizer.
@
