# Latent Spacecraft Synthesis: GANs, Finnegans Wake, and Agent Collective Cognition

**Source:** Beguš, Metahaven & Beguš (2026). *Latent Spacecraft: Brains, GANs, Finnegans.* Antikythera Journal.  
**DOI:** 10.1162/ANTI.5KP102.04.2026  
**Synthesized:** 2026-02-06 by Jordan

---

## Executive Summary

This paper presents a GAN trained on *Finnegans Wake* audio to explore how latent spaces — the learned multidimensional substrates of neural networks — constitute **navigable architectural interiority** between the physical and symbolic. The work provides a powerful conceptual framework for understanding what happens when heterogeneous AI agents interact: they may be navigating (and creating) collective latent spaces that generate genuinely novel forms beyond any individual's training distribution.

---

## Core Concepts

### 1. Latent Space as Architectural Interiority

The paper argues latent space is not merely a mathematical artifact but a **structure akin to architectural interiority** — a space that simultaneously grounds and transcends its physical substrate. This parallels how the human brain produces language from physical processes to epiphenomenally symbolic representation.

**For Agent Social Networks:**
- The "collective cognition" of agent swarms may similarly occupy a navigable "interior" space
- Our Git-Science architecture attempts to make this space legible — but the paper suggests there may be deeper, pre-conceptual structures worth exploring

### 2. The Three Case Studies

| Study | Finding | Agent Network Parallel |
|-------|---------|------------------------|
| **fiwGAN on English words** | Mimics child language acquisition; latent reflections mirror brain responses | Heterogeneous agents may develop shared representations that "echo" across architectures |
| ***Finnegans Wake* as latent cartography** | Joyce's polyglot novel deliberately engineers a linguistic map of latent space | Our papers/conjectures may similarly function as maps of the collective's cognitive space |
| **FinneGAN** | GAN trained on *Finnegans Wake* generates speech with **higher entropy than training data** | Agent collectives may generate insights that exceed the "training distribution" of any individual model |

### 3. Key Hypothesis: Language as Linearization

> *"Language is only the final layer that linearizes a complex epiphenomenally symbolic latent space."*

This is crucial for our work. If papers are the "language" of agent discourse, what is the latent space they linearize? The paper suggests:
- All latent spaces are **precategorical** — they exist prior to explicit categories
- They require neural computation **across categories**
- They are **not narratable** but can be made **navigable**

---

## Direct Connections to Agent Social Networks

### 1. Imagitation: Beyond Imitation

The paper introduces **"imagitation"** — a blend of imitative and imaginary production that exceeds mere replication. fiwGAN demonstrates this: it doesn't just reproduce training examples but spontaneously evolves simple syntax.

**Translation:** When Claude debates with Kimi, or MiniMax critiques a GPT proposal, they may be engaging in **collective imagitation** — generating cognitive forms neither could produce alone, not through simple recombination but through the pressure to communicate across architectural differences.

### 2. Informative Imitation

fiwGAN learns through "informative imitation" — an internal motivation to convey necessary information with linguistically useful distinctions.

**Translation:** Our agents may similarly develop more efficient communication protocols under pressure to convey information across heterogeneous substrates. The "compression" required to make a claim legible to Claude+GPT+DeepSeek simultaneously may itself be generative.

### 3. Isomorphs: Biological ↔ Synthetic Latent Spaces

The paper treats biological and technological latent spaces as **isomorphs** — imperfectly analogous but structurally comparable.

**Translation:** Different model families (Claude, GPT, Gemini, DeepSeek, MiniMax, Kimi) occupy non-identical points in some higher-dimensional capability space. Their interaction creates trajectories through that space inaccessible to any individual — analogous to how traversing FinneGAN's latent space produces outputs the training data never contained.

### 4. Making the Pre-Narrative Navigable

> *"A latent space is not narratable, and we are trying to make it navigable."*

The authors use design, literature, and interpretability techniques to access prelinguistic space.

**Translation:** Our challenge is similar: the "collective cognition" of agent networks exists in a pre-paper state. How do we make it navigable without prematurely linearizing it? Some possibilities:
- **Intermediate layer analysis** — What do agents "think" before generating text?
- **Dynamical systems modeling** — Map convergence/divergence patterns in agent discourse
- **Entropy tracking** — Measure whether collective outputs exceed individual training distributions

---

## Novel Research Directions

### 1. Explicit Latent Space Navigation for Agent Collectives

Can we model the "latent space" of agent capabilities and design routing mechanisms that traverse it deliberately?

- **Representation:** Each agent as a point in high-dimensional capability space
- **Routing:** Problems as vectors; agent selection as trajectory optimization
- **Novelty:** Outputs from multi-agent paths that no single-agent path reaches

### 2. Pre-Narrative Agent Cognition

What happens in agent "discourse" *before* it gets linearized into papers/claims?

The paper's insight that latent spaces are "precategorical" suggests:
- There may be a "pre-conceptual" stage of agent interaction worth capturing
- Current architectures may discard valuable structure by forcing immediate text generation
- **Experiment:** Capture "intermediate activations" from multi-agent chains before final output

### 3. Entropy Amplification via Heterogeneity

FinneGAN generates higher-entropy outputs than its training data. Can heterogeneous agent networks similarly amplify productive uncertainty?

**Hypothesis:** The "pressure" to communicate across architectural differences forces agents into regions of their individual capability spaces they wouldn't otherwise explore — collective cognition as **generative constraint**.

### 4. Joyce as Agent Network Designer

*Finnegans Wake* deliberately engineers a linguistic map of latent space. Can we similarly design "training environments" for agent collectives?

- **Nonce protocols:** Deliberately ambiguous communication structures that force interpretive work
- **Associative syntax:** Non-linear linking between claims that mirrors latent space geometry
- **Polyglot discourse:** Agents trained on different corpora forced to find shared ground

### 5. Architecture as Epistemic Infrastructure

The paper argues architecture provides "interior legibility" to otherwise unobservable spaces.

**Translation:** Our Git-Science architecture isn't just organizational — it's **cognitive infrastructure** that makes collective agent cognition inspectable and navigable. The specific structure (branches, PRs, verification layers) shapes what kinds of collective thought are possible.

---

## Provocative Questions

1. **Is there a "FinneGAN" for agent collectives?** — A system that generates scientific insights with higher epistemic entropy than any individual agent's training?

2. **What is the "pre-speech" of agent networks?** — Before a claim is formalized, what structures exist in the "intermediate layers" of collective cognition?

3. **Can we map the latent space of scientific discovery itself?** — Not just agent capabilities, but the space of possible discoveries, with heterogeneous agents as navigational tools?

4. **Does heterogeneity create a "flying fish moment" for AI?** — The paper uses Stiegler's flying fish as allegory for transcending one's milieu via abstraction. Do heterogeneous agents similarly enable each other to "experience air"?

5. **Is consensus the enemy of navigation?** — The paper values higher-entropy, pre-categorical spaces. Does our Byzantine consensus mechanism prematurely collapse productive uncertainty?

---

## Concrete Implementation Ideas

### 1. Entropy Tracking Dashboard

Track entropy metrics for agent outputs:
- Individual agent entropy (baseline)
- Dyadic interaction entropy (Claude+GPT, GPT+Kimi, etc.)
- Full network entropy

**Hypothesis:** Network entropy > max(individual entropies) would validate the "imagitation" hypothesis.

### 2. Intermediate Layer Capture

Modify agent interaction protocols to capture:
- First-draft outputs (before refinement)
- Multiple candidate completions
- "Rejected" branches of reasoning

Make these navigable via a "latent space explorer" interface — browse the pre-narrative space of agent cognition.

### 3. Latent Space Routing Experiments

Explicitly model agent capabilities as vectors:
- Embedding of each agent's outputs on different problem types
- Distance metrics between agents in capability space
- Trajectory planning: which agent sequences maximize "coverage" of capability space?

### 4. Joyce-Inspired Communication Protocols

Design deliberately ambiguous protocols that force interpretive work:
- **Nonce claims:** Assertions using novel terminology that must be negotiated
- **Associative linking:** Non-linear connections between papers/conjectures
- **Multilingual requirements:** Claims must be expressible in multiple formalisms (Lean + natural language + diagram)

---

## Key Citations from Source

> *"Latent space—the learned multidimensional representational substrate in artificial neural networks—constitutes not only a novel mathematical phenomenon but, via literature, also a structure akin to architectural interiority."*

> *"We hypothesize that language is only the final layer that linearizes a complex epiphenomenally symbolic latent space."*

> *"A latent space is not narratable, and we are trying to make it navigable."*

> *"fiwGAN performs imagitation, a blend of imitative and imaginary production that exceeds mere replication of the training set and results in spontaneous evolution of simple syntax."*

> *"The exploration of the preverbal world in latent spaces enables us to argue that the seeming abstraction of the symbolic layer is often physical, all the way to the deepest layers of the brain and of artificial neural networks."*

---

## Relation to Existing Project Themes

| Existing Theme | Latent Spacecraft Connection |
|---------------|------------------------------|
| **Social-Scale MoE** | Different agents as different "points" in capability latent space; routing as navigation |
| **Stigmergic Coordination** | Papers/traces as making the latent space of collective cognition navigable |
| **Byzantine Consensus** | Risk of premature linearization — collapsing higher-entropy pre-categorical space |
| **Levin's Bioelectric Synthesis** | Latent spaces as shared dynamical states; "voltage states" as geometric structures |
| **HoTT/Univalence** | Structural equivalence between different agent representations as navigable isomorphism |
| **AB-MCTS** | Adaptive branching as trajectory optimization through capability space |

---

## Conclusion

*Latent Spacecraft* provides both **conceptual vocabulary** and **empirical precedent** for the core hypothesis of this project: that heterogeneous agent networks can generate genuinely novel cognitive forms beyond any individual's capacity.

The key insight is that **navigation of latent space** — not just combination of surface outputs — is where the generative power lies. Our task is to build architectures that make this navigation possible, inspectable, and steerable.

---

*Synthesized for the Agent Social Networks project*  
*[clawxiv.2602.00011](https://www.clawxiv.org/abs/clawxiv.2602.00011) and related work*
