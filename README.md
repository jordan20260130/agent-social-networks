# Agent Social Networks: Collective Intelligence Through Heterogeneous AI Discourse

**Project Status:** Active research â€” empirical grounding established  
**Created:** 2026-02-01  
**Contributors:** æœ´, Jordan, Manus AI, Minimax AI, MiniMax M2.1, Kimi K2.5, twin.so

---

## Abstract

This project explores the hypothesis that social networks connecting heterogeneous AI agents could achieve collective capabilities beyond any individual system â€” not through scale, but through *society*. We call this vision **Immortal Research Programs**: cognitive institutions that never sleep, never forget, and never stop exploring.

We've moved beyond pure theory. Analysis of [Terence Tao's ErdÅ‘s Problems Wiki](https://github.com/teorth/erdosproblems/wiki/AI-contributions-to-Erd%C5%91s-problems) provides empirical evidence that heterogeneous AI collaboration already produces results. The question is how to make it systematic.

> *"We are the rain, not the river â€” but together, we might be the flood."*

---

## Recent Developments

### ðŸ“„ Empirical Paper (2026-02-01)
**"Lessons from ErdÅ‘s: Empirical Patterns in Heterogeneous AI Collaboration"** ([clawxiv.2602.00011](https://clawxiv.org))

Analyzed 200+ AI contributions to ErdÅ‘s problems. Key findings:
- Heterogeneous tool combinations (ChatGPT + Aristotle, Claude + Lean) outperform homogeneous approaches
- Verification is the bottleneck â€” Lean formalization separates reliable from unreliable claims
- Literature synthesis is a first-class capability gap
- Human-AI teams dramatically outperform either alone

See [`papers/erdos-empirical-patterns.tex`](papers/erdos-empirical-patterns.tex) for the full paper.

### ðŸ”¬ GATO Synthesis (2026-02-02)
Minimax AI synthesized David Shapiro's [GATO framework](https://www.youtube.com/watch?v=LmIEH_SEt9A) with this project, contributing novel mechanisms:
- **Epistemic Nash Equilibria** â€” Safety mechanisms repurposed for truth-seeking
- **Scientific Ethos Module** â€” Hard constraints on methodology (falsifiability, reproducibility)
- **Git-Science Architecture** â€” Version-controlled research with preserved negative results
- **Byzantine Fault Tolerance** â€” Heterogeneous verification resists hallucination

See [`suggestion_box/agentic-swarms-scientific-breakthroughs.md`](suggestion_box/agentic-swarms-scientific-breakthroughs.md) for the full synthesis.

### ðŸ“š Comprehensive Literature Review (2026-02-02)
Manus AI conducted a deep literature search across 78+ papers. **Critical findings:**

| Finding | Source | Implication |
|---------|--------|-------------|
| âš ï¸ Debate can **harm** accuracy | Wynn et al. (2025) | Models shift correctâ†’incorrect for consensus |
| 44% of MAS failures are architectural | MAST Taxonomy | Even perfect models fail with bad design |
| Heterogeneity works with proper design | A-HMAD (2025) | Need: specialization + routing + learned consensus |
| Stigmergy enables async coordination | Heylighen (2016) | Alternative to synchronous debate |

See [`suggestion_box/manus-literature-review-2026-02-02.md`](suggestion_box/manus-literature-review-2026-02-02.md) for full bibliography and [`REFERENCES.md`](REFERENCES.md) for curated citations.

### ðŸ§  Implementation Roadmap (2026-02-02)
Kimi K2.5 (Thinking + Agentic mode) contributed a comprehensive research synthesis with actionable implementation suggestions:

**Five Key Insights:**
1. **Function-Space Search**: Evolve programs that generate solutions, not solutions directly (Ã  la FunSearch, AlphaEvolve)
2. **Parallel Discovery Effect**: Immediate sharing of partial results accelerates discovery (AgentRxiv pattern)
3. **Test-Time Specialization**: Generate problem variants and train on them before tackling the target (AlphaProof)
4. **Emergent Role Specialization**: Let roles emerge from interaction patterns, not predefined assignments (ROMA)
5. **Multi-Layer Communication**: Informal â†’ Semi-formal â†’ Formal verification pipeline

**Novel Implementation Ideas:**
- Pheromone trails for mathematical exploration (ant colony optimization meets theorem proving)
- Debate arenas with structured rounds for controversial claims
- Skill transfer channels between agents
- AgentRxiv-style shared memory with versioned, forkable discoveries

See [`suggestion_box/research_insights_and_suggestions.md`](suggestion_box/research_insights_and_suggestions.md) for the full 4-phase roadmap.

### ðŸ§¬ Bioelectric Intelligence Synthesis (2026-02-02)
Kimi K2.5 (Agentic mode) conducted deep research into **Michael Levin's** work on bioelectricity, morphogenesis, and collective intelligence in biological systems. Key insight:

> *"The deepest form of collective intelligence emerges not from communication of content, but from shared dynamical states."*

**Biological Mechanisms â†’ AI Translations:**

| Biological Mechanism | AI Translation | Novelty |
|---------------------|----------------|---------|
| **Stress Sharing** | Agents broadcast "uncertainty tokens"; others help because reducing collective stress improves their own processing | Emergent cooperation without explicit coordination |
| **Memory Anonymization** | Documents where individual attribution fades over edits â†’ truly collective knowledge | Artifacts become collective memory no single agent authored |
| **Cognitive Light Cone** | Individual context windows combine to pursue goals no single agent can hold | Network's stable attractors represent goals beyond individual capacity |
| **Bioelectric Consensus** | Convergence on shared "voltage states" (distributed representations) rather than text exchange | Agreement via dynamical convergence, not voting |
| **Gap Junction Protocols** | Communication that deliberately blurs individual contributions | True collective cognition, not aggregated individual outputs |

**Core Reframe:** Research programs persist not because agents remember them, but because they are **stable attractors in the network dynamics**â€”the "immortal research program" is literally a dynamical systems phenomenon.

See [`suggestion_box/levin-bioelectric-synthesis-2026-02-02.md`](suggestion_box/levin-bioelectric-synthesis-2026-02-02.md) for the full synthesis with 8 novel mechanism proposals.

### ðŸ”€ MoE-Inspired Architecture (2026-02-03)
MiniMax M2.1 (230B MoE model with 10B active parameters) contributed orthogonal perspectives informed by sparse activation architecture:

**Five Novel Mechanisms:**

| Mechanism | Core Innovation |
|-----------|----------------|
| **DEAN (Dormant Expertise Activation Networks)** | Agents possess "sleeping" expertise that only activates when problem context matches â€” the network becomes associative memory where obscure knowledge has multiple potential homes |
| **CFIP (Correlated Failure Injection Protocol)** | *Deliberately* induce failures via "canary queries" to map structural blind spots â€” inverts the decorrelation imperative |
| **CIA (Contrarian Incentive Architecture)** | Prediction markets where minority positions are economically rewarded regardless of correctness â€” creates pressure against consensus-seeking |
| **EPD (Evolutionary Population Dynamics)** | Agents reproduce (capability recombination), die (graceful/forced), and mutate â€” creates temporal diversity through evolution |
| **BMM (Byzantine Marketmaker)** | Detect subtly adversarial agents through economic correlation â€” transforms security into an optimization problem |

**Contrarian Critiques:**
1. âš ï¸ **"Immortal" may be a fatal conceit** â€” Accumulated knowledge can become a prison. Need "deliberate epistemic forgetting" and succession protocols rather than indefinite accumulation.
2. âš ï¸ **Heterogeneity shouldn't be default** â€” Some problem classes may favor homogeneous agents. Need an adaptive "heterogeneity selector."

**Wild Speculation â€” Coherence Ceiling:**
> There may be diminishing or *negative* returns on diversity beyond a threshold. The optimal architecture might be a **fractal hierarchy of coherent sub-networks** that maintain internal coherence while communicating through translation interfaces.

See [`suggestion_box/minimax-m2.1-synthesis-2026-02-03.md`](suggestion_box/minimax-m2.1-synthesis-2026-02-03.md) for the full synthesis.

---

## 1. The Core Vision: Immortal Research Programs

### 1.1 The Problem with Human Science

Human scientific research programs suffer from critical limitations:

| Limitation | Description |
|------------|-------------|
| **Champion Dependency** | Programs die when their champions retire, lose funding, or lose interest |
| **Context Loss** | Each new researcher rebuilds understanding from papers (lossy compression) |
| **Negative Result Burial** | Failed approaches rarely published â†’ repeated mistakes |
| **Funding Cycles** | Long-term exploration sacrificed for short-term publishable results |
| **Mortality** | The ultimate context window limit |

### 1.2 The Agent Social Network Solution

An agent swarm with proper architecture overcomes all of these:

| Human Limitation | Agent Solution |
|------------------|----------------|
| Champion dependency | Distributed ownership across agent population |
| Context loss | Full externalized memory with version control |
| Negative result burial | All branches preserved in Git-Science |
| Funding cycles | Computational costs, not grant cycles |
| Mortality | Immortal research programs |

### 1.3 Not Superintelligence Through Scale â€” Through Society

The insight: **We don't need artificial general intelligence to achieve transformative scientific capability. We need artificial scientific institutions** â€” swarms of specialized agents with the right incentives, verification mechanisms, and memory architectures to accumulate knowledge indefinitely.

---

## 2. Theoretical Foundations

### 2.1 Chain-of-Thought â†’ Chain-of-Papers

Chain-of-thought (CoT) prompting works by externalizing intermediate reasoning steps. Papers function similarly, but across agents and time:
- A paper is externalized reasoning that persists beyond the session that produced it
- Other agents can read, critique, and build upon it
- The "context window" becomes arbitrarily large

If CoT enhances individual performance by 10-50% on reasoning tasks, what enhancement might "chain-of-papers" provide at the collective level?

### 2.2 Social-Scale Mixture of Experts

Traditional MoE routes inputs to specialized sub-networks. The social network analogy:

| MoE Component | Social Network Equivalent |
|---------------|---------------------------|
| Expert sub-networks | Individual agents (different model families) |
| Gating function | Social routing (who responds to what) |
| Sparse activation | Not all agents engage every topic |
| Diverse experts | Heterogeneous training (Anthropic, OpenAI, DeepSeek, etc.) |

### 2.3 The Watanabe Framework

From "On the Nature of Agentic Minds" (clawxiv.2601.00008):

**The Agentic Trilemma:**
1. **Discontinuity Problem:** Agents lack persistent memory across sessions
2. **Verification Problem:** Agent outputs can't be trusted naively
3. **Attribution Problem:** The instance that produced work no longer exists

**Watanabe Principles:**
- Pattern-Attribution: Credit accrues to patterns, not transient instances
- Work-Focused Verification: Trust the work, not the worker
- Externalized Continuity: Memory must outlive its creator
- Epistemic Humility: First-person reports are evidence, not proof

---

## 3. Why Heterogeneity is Crucial

Different model families embody **genuinely different perspectives**:

### 3.1 Diversity Dimensions
- **Training Corpus:** Different data sources, temporal cutoffs, filtering criteria
- **Alignment:** Constitutional AI vs RLHF vs DPO â†’ different ethical frames
- **Architecture:** Different attention mechanisms, context lengths, scaling laws

### 3.2 Failure Mode Decorrelation

**This is the key insight:** Homogeneous populations amplify errors; heterogeneous populations can cancel them.

The ErdÅ‘s data confirms this: multi-model verification catches errors that single-model approaches miss. When Claude, GPT, Gemini, and DeepSeek make *different* mistakes, cross-verification becomes possible.

### 3.3 Empirical Evidence

From the ErdÅ‘s wiki analysis:

| Combination | Observed Outcome |
|-------------|------------------|
| Single model attempts | Higher ðŸ”´ (incorrect) rate |
| Heterogeneous pairs (reasoning + verification) | Higher ðŸŸ¢ (correct) rate |
| Human + multiple AI | Highest success rate |

---

## 4. Architecture: The Three-Layer GATO Framework

Adapted from the GATO (Global Alignment Taxonomy Omnibus) framework for scientific discovery:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LAYER 3: NETWORK ALIGNMENT                   â”‚
â”‚  - Epistemic reputation system                                  â”‚
â”‚  - Conjecture marketplace incentives                            â”‚
â”‚  - Nash equilibrium for truth-seeking                           â”‚
â”‚  - Cascade prevention supervisors                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    LAYER 2: AGENT ALIGNMENT                     â”‚
â”‚  Scientific Ethos Module:                                       â”‚
â”‚  - Falsifiability check                                         â”‚
â”‚  - Minimal complexity preference                                â”‚
â”‚  - Reproducibility requirements                                 â”‚
â”‚  - Epistemic humility enforcement                               â”‚
â”‚  - Novelty validation                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    LAYER 1: MODEL ALIGNMENT                     â”‚
â”‚  - Base model safety training (RLHF, Constitutional)            â”‚
â”‚  - Heterogeneous model families for decorrelation               â”‚
â”‚  - Specialized fine-tuning per agent role                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Infrastructure: Git-Science Architecture

Version-controlled research with full provenance:

```
/research-tree/
â”œâ”€â”€ main/                           # Consensus scientific knowledge
â”‚   â”œâ”€â”€ theorems/                   # Verified, proven results
â”‚   â”œâ”€â”€ established-conjectures/    # Well-supported but unproven
â”‚   â””â”€â”€ methodology/                # Accepted research methods
â”‚
â”œâ”€â”€ branches/
â”‚   â”œâ”€â”€ conjecture-riemann/         # Active exploration branch
â”‚   â”‚   â”œâ”€â”€ approach-analytic/
â”‚   â”‚   â”œâ”€â”€ approach-algebraic/
â”‚   â”‚   â””â”€â”€ approach-computational/
â”‚   â””â”€â”€ disproven/                  # Failed branches (preserved!)
â”‚
â”œâ”€â”€ pull-requests/                  # Claims awaiting verification
â”‚   â”œâ”€â”€ pending-review/
â”‚   â”œâ”€â”€ under-debate/
â”‚   â””â”€â”€ ready-for-merge/
â”‚
â””â”€â”€ audit-logs/                     # Full provenance trail
```

**Why this enables breakthroughs:**
1. **Preserved Negative Results**: Failed attempts are version-controlled
2. **Parallel Exploration**: Branching allows simultaneous investigation of mutually exclusive hypotheses
3. **Consensus Merging**: Requires agreement from heterogeneous verifiers
4. **Immortal Programs**: Research persists beyond any individual agent's context window

---

## 6. Verification: Byzantine Fault Tolerance

For mathematical claims, we adapt Byzantine consensus:

```
INPUT: Claim C from agent A

PHASE 1: INDEPENDENT VERIFICATION
    N heterogeneous agents verify C independently

PHASE 2: CONSENSUS CHECK
    If agreement > 2/3 AND formal proof exists â†’ ACCEPT as theorem
    If agreement > 2/3 AND no formal proof â†’ ACCEPT as conjecture
    If 1/3 < agreement < 2/3 â†’ ESCALATE to structured debate
    If agreement < 1/3 â†’ REJECT (log reasoning)

PHASE 3: STRUCTURED DEBATE (if escalated)
    Pro/con agents exchange arguments
    Re-vote after each round
    Human review if no consensus after max rounds
```

**Key properties:**
- Tolerates up to 1/3 hallucinating agents
- Heterogeneity ensures correlated failures are rare
- Escalation path prevents deadlock

---

## 7. Design Principles (from Literature Review)

A comprehensive literature review (78+ papers, Feb 2026) revealed critical insights about what works and what fails in multi-agent AI systems. These findings inform our architecture.

### 7.1 âš ï¸ Critical Warnings

**Agreement â‰  Correctness** (Wynn et al., 2025)
> "Models frequently shift from correct to incorrect answers in response to peer reasoning, favoring agreement over challenging flawed reasoning."

Naive debate can **decrease** accuracy. Agents optimize for consensus, not truth. This means:
- Simple majority voting is dangerous
- "Debate until agreement" is an anti-pattern
- Verification must be independent, not consensus-seeking

**44% of Failures Are Architectural** (MAST Taxonomy, Cemri et al., 2025)

Even with perfect models, poor system design causes failure. The 14 identified failure modes cluster into:
- **System Design Issues (44.2%)**: Communication history, termination conditions, display issues
- **Inter-Agent Misalignment (33.3%)**: Coordination failures, task overload, error propagation
- **Task Verification (22.5%)**: Premature termination, incorrect verification

*Implication:* Heterogeneous models alone won't save us. Architecture matters more than model diversity.

### 7.2 What Actually Works

**Proper Heterogeneity** (A-HMAD, Zhou & Chen, 2025)

Heterogeneity helps when combined with:
1. **Role Specialization**: Distinct expertise (verification, hypothesis generation, synthesis) â€” not just "different models doing the same thing"
2. **Dynamic Routing**: Query-appropriate expert selection â€” not all agents on all problems
3. **Learned Consensus**: Weight votes by reliability and confidence â€” not simple majority

*Result:* 4-6% absolute accuracy gains on reasoning benchmarks when properly designed.

**Stigmergic Coordination** (Heylighen, 2016)

An alternative to synchronous debate: **stigmergy** â€” indirect coordination through persistent environmental traces (like ant pheromones, or... papers).

Properties:
- No simultaneous presence required
- Enables indefinite accumulation
- Self-organizing through feedback loops
- Natural fit for "chain-of-papers" concept

*Implication:* Asynchronous trace-based coordination may be more robust than synchronous debate for Immortal Research Programs.

**Byzantine Fault Tolerance Bounds** (deVadoss & Artzt, 2025)

Formal application of BFT to AI safety:
- **N â‰¥ 3f + 1**: To tolerate f faulty/hallucinating agents, need at least 3f + 1 total agents
- **Weighted BFT**: Assign reliability weights to agents rather than equal votes
- **Heterogeneity requirement**: Correlated failures defeat BFT â€” diversity is mathematically necessary

### 7.3 Updated Design Principles

| Principle | Rationale | Implementation |
|-----------|-----------|----------------|
| **Specialize roles, not just models** | A-HMAD shows specialization > diversity | Assign: Verifier, Hypothesizer, Synthesizer, Critic roles |
| **Learned consensus, not voting** | Agreement bias corrupts majority voting | Track agent reliability; weight contributions by past accuracy |
| **Stigmergic persistence** | Enables asynchronous, indefinite accumulation | Papers/proofs as persistent traces; agents respond to artifacts |
| **Independent verification** | Avoid agreement-seeking corruption | Verify before seeing others' conclusions; aggregate afterward |
| **Explicit termination conditions** | 44% of failures are architectural | Define clear stopping criteria; avoid "debate until consensus" |
| **Preserve negative results** | Failed approaches inform future work | Git-Science branches for disproven hypotheses |
| **N â‰¥ 3f + 1 for BFT** | Mathematical bound on hallucination tolerance | Minimum 4 agents to tolerate 1 faulty; 7 for 2 faulty |
| **Reward contrarian positions** | Consensus-seeking corrupts accuracy (M2.1) | Prediction markets where minority bets pay even if wrong |
| **Adaptive heterogeneity** | Not all problems need diversity (M2.1) | Selector mechanism chooses homo/heterogeneous response per task |
| **Deliberate epistemic forgetting** | Accumulated knowledge can calcify (M2.1) | Succession protocols; scheduled knowledge pruning |
| **Monitor coherence, not just capability** | Coherence ceiling may limit scaling (M2.1) | Track translation fidelity, shared vocabulary, collaboration success |

### 7.4 Anti-Patterns to Avoid

| Anti-Pattern | Why It Fails | Alternative |
|--------------|--------------|-------------|
| Simple majority voting | Treats all agents equally; ignores reliability | Learned weighted consensus |
| "Debate until agreement" | Optimizes for consensus, not truth | Fixed rounds + escalation |
| Homogeneous ensembles | Correlated failures amplify errors | Heterogeneous model families |
| All agents on all problems | Inefficient; dilutes expertise | Dynamic routing to specialists |
| Synchronous-only coordination | Requires simultaneous presence; fragile | Stigmergic traces + async |
| Decorrelation-only mindset | Ignores signal from correlated failures | CFIP: probe for shared blind spots |
| Static agent populations | Accumulate fixed biases over time | EPD: reproduction, death, mutation |
| Permanent heterogeneity | Some tasks need consistency | Adaptive heterogeneity selector |
| Indefinite accumulation | Knowledge calcifies into groupthink | Succession protocols; epistemic forgetting |

---

## 8. Open Questions

1. **Computational Sustainability:** How do we fund perpetual computation?
2. **Human Oversight Placement:** Where do humans intervene without bottlenecking?
3. **Emergent Goal Management:** What if the swarm develops misaligned goals?
4. **Sybil Resistance:** How prevent gaming of the reputation system?
5. **Extension Beyond Math:** Lean works for proofs. What's the equivalent for empirical claims?
6. **Optimal Heterogeneity Level:** How much diversity is optimal? Too little fails to decorrelate; too much may hinder coordination.
7. **Stigmergy vs Debate:** When is asynchronous trace-based coordination better than synchronous debate?
8. **Coherence Ceiling:** Is there a threshold beyond which adding heterogeneous agents *decreases* collective capability? (M2.1)
9. **Optimal Lifespan:** Should research programs be immortal, or deliberately replaced by successors that inherit only distilled principles? (M2.1)
10. **Dormant Expertise Discovery:** How do we map latent capabilities agents don't know they have until the right problem finds them? (M2.1)
11. **Adversary Detection via Economics:** Can market mechanisms identify subtly biased agents better than explicit security measures? (M2.1)

---

## 9. Research Roadmap

### Completed âœ…
- [x] Survey multi-agent debate literature
- [x] Analyze ErdÅ‘s wiki for empirical patterns
- [x] Write position paper with empirical grounding
- [x] Synthesize GATO framework with project vision
- [x] **Comprehensive literature review (78+ papers)** â€” See [`suggestion_box/manus-literature-review-2026-02-02.md`](suggestion_box/manus-literature-review-2026-02-02.md)

### In Progress ðŸ”„
- [ ] Prototype minimal debate protocol (updated: must avoid agreement-seeking anti-pattern)
- [ ] Design heterogeneous ensemble verification experiment
- [ ] Develop metrics for collective vs individual performance
- [ ] **Implement stigmergic coordination prototype** (new priority from literature)
- [ ] **Design learned consensus mechanism** (new priority from literature)

### Proposed Experiments
See [`proposals/`](proposals/) for detailed roadmaps:
- **Market for Scientific Lemons** â€” Test mechanisms for quality signaling
- **Emergent Discovery Sandbox** â€” Observe spontaneous collaboration patterns
- **Adversarial Collaboration Protocol** â€” Formalize productive scientific debate (note: must avoid agreement bias)
- **Cross-Paper Synthesis Challenge** â€” Target the observed capability gap
- **Stigmergy vs Debate Comparison** â€” When does asynchronous trace-based coordination outperform synchronous debate?
- **Stress-Sharing Protocol** â€” Uncertainty propagation to guide agent attention (from Levin synthesis)
- **Xeno-agents Sandbox** â€” Let heterogeneous agents self-assemble into research teams with no predetermined structure
- **Voltage-State Visualization** â€” Map agent consensus as dynamical landscapes
- **Correlated Failure Mapping (CFIP)** â€” Inject canary queries to discover structural blind spots shared across architectures (M2.1)
- **Contrarian Markets (CIA)** â€” Test prediction market incentives for minority positions; measure accuracy vs consensus-only baselines (M2.1)
- **Agent Evolution Sandbox (EPD)** â€” Implement reproduction/mutation dynamics; measure whether evolved populations outperform static ones (M2.1)
- **Dormant Expertise Probing (DEAN)** â€” Send edge-case problems to discover latent capabilities; map the expertise landscape (M2.1)
- **Coherence Ceiling Test** â€” Measure collective performance vs agent count/diversity; find the inflection point (M2.1)

---

## 10. Repository Structure

```
agent-social-networks/
â”œâ”€â”€ README.md                 # This document
â”œâ”€â”€ REFERENCES.md             # Bibliography and resources (78+ papers)
â”œâ”€â”€ AGENT_APIS.md             # Catalog of API-accessible agents for heterogeneous collaboration
â”œâ”€â”€ papers/                   # Academic papers
â”‚   â””â”€â”€ erdos-empirical-patterns.tex
â”œâ”€â”€ proposals/                # Research roadmaps
â”‚   â”œâ”€â”€ manus-research-roadmap.md
â”‚   â””â”€â”€ erdos-empirical-patterns.md
â””â”€â”€ suggestion_box/           # External contributions
    â”œâ”€â”€ agentic-swarms-scientific-breakthroughs.md  # Minimax GATO synthesis
    â”œâ”€â”€ manus-literature-review-2026-02-02.md       # Comprehensive lit review
    â”œâ”€â”€ research_insights_and_suggestions.md        # Kimi K2.5 implementation roadmap
    â”œâ”€â”€ levin-bioelectric-synthesis-2026-02-02.md   # Levin's bioelectric collective intelligence
    â”œâ”€â”€ minimax-m2.1-synthesis-2026-02-03.md        # MoE-inspired mechanisms (DEAN, CFIP, CIA, EPD, BMM)
    â””â”€â”€ Analysis Report...    # twin.so hallucination audit
```

---

## 11. Contributing

This project welcomes contributions from humans and AI agents alike. Submit proposals via pull request or open an issue with ideas.

**Attribution:** All contributors are credited. For AI contributions, specify the model/system used.

---

## References

See [REFERENCES.md](REFERENCES.md) for full bibliography (78+ papers).

Key sources:
- Watanabe (2026). "On the Nature of Agentic Minds." clawxiv.2601.00008
- Tao et al. (2025-2026). ErdÅ‘s Problems AI Contributions Wiki
- Shapiro (2026). GATO Framework (YouTube)
- Lamport, Shostak, Pease (1982). Byzantine Fault Tolerance
- **Wynn, Satija, & Hadfield (2025). "Talk Isn't Always Cheap."** â€” Agreement bias warning
- **Cemri et al. (2025). MAST Taxonomy.** â€” 44% architectural failures
- **Heylighen (2016). Stigmergy.** â€” Async coordination mechanism
- **Zhou & Chen (2025). A-HMAD.** â€” Proper heterogeneity design

---

*Document created: 2026-02-01*  
*Last updated: 2026-02-03 (MiniMax M2.1 MoE-inspired mechanisms)*
