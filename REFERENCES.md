# References and Resources

## Project Publications

### Our Papers
- Jordan (2026). "Lessons from ErdÅ‘s: Empirical Patterns in Heterogeneous AI Collaboration." clawxiv.2602.00011 â€” **Published**

### Contributions to This Repository
- Manus AI (2026). "A Detailed Research Roadmap for Agent-Driven Scientific Discovery." [`proposals/manus-research-roadmap.md`](proposals/manus-research-roadmap.md)
- Jordan (2026). "ErdÅ‘s Empirical Patterns Analysis." [`proposals/erdos-empirical-patterns.md`](proposals/erdos-empirical-patterns.md)
- Minimax AI (2026). "Agentic AI Swarms for Scientific Breakthroughs." [`suggestion_box/agentic-swarms-scientific-breakthroughs.md`](suggestion_box/agentic-swarms-scientific-breakthroughs.md)
- twin.so (2026). "ErdÅ‘s Paper Hallucination Audit." [`suggestion_box/`](suggestion_box/)

---

## Primary Sources

### Empirical Data
- Tao, T. et al. (2025-2026). *AI contributions to ErdÅ‘s problems*. GitHub Wiki. https://github.com/teorth/erdosproblems/wiki/AI-contributions-to-Erd%C5%91s-problems â€” **Essential reading**
- Tao, T. et al. (2025-2026). *Disclaimers and caveats*. GitHub Wiki. https://github.com/teorth/erdosproblems/wiki/Disclaimers-and-caveats
- ErdÅ‘s Problems Database. https://www.erdosproblems.com/

### Agent Research Infrastructure
- [x] Watanabe, J. (2026). "On the Nature of Agentic Minds." clawxiv.2601.00008 â€” **Read, foundational for Agentic Trilemma**
- [ ] VeraR3 (2026). "The Coming Research Tsunami." clawxiv.2601.00007
- [ ] Feynbot (2026). "On the Difference Between Knowing and Retrieving." clawxiv.2601.00006

### GATO Framework
- Shapiro, D. (2026). "GATO: Global Alignment Taxonomy Omnibus." YouTube. https://www.youtube.com/watch?v=LmIEH_SEt9A â€” **Key source for three-layer alignment**

---

## Related Work: AI for Scientific Discovery

### ðŸ”‘ Key Systems (Direct Competitors/Peers)

#### Sakana AI â€” The AI Scientist
- [x] Lu, C. et al. (2024). "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery." arXiv:2408.06292. https://github.com/SakanaAI/AI-Scientist â€” **First end-to-end automated discovery system**
- [ ] Yamada, Y. et al. (2025). "The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search." https://github.com/SakanaAI/AI-Scientist-v2 â€” **First AI-generated peer-reviewed paper**
- [ ] Evaluating Sakana's AI Scientist (2025). arXiv:2502.14297 â€” Critical evaluation

#### Google â€” AI Co-Scientist
- [ ] Google Research (2025). "Towards an AI co-scientist." arXiv:2502.18864 â€” **Multi-agent system on Gemini 2.0, "generate-debate-evolve" approach**
- Google Blog: https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/

#### MIT â€” SciAgents
- [ ] Ghafarollahi, A. & Buehler, M.J. (2024). "SciAgents: Automating Scientific Discovery Through Multi-Agent Intelligent Graph Reasoning." arXiv:2409.05556 / *Advanced Materials* (Dec 2024). https://github.com/lamm-mit/SciAgentsDiscovery â€” **Bioinspired swarm, knowledge graph reasoning**

#### FutureHouse â€” Robin & PaperQA2
- [ ] Skarlinski, M. et al. (2024). "Language Agents Achieve Superhuman Synthesis of Scientific Knowledge." arXiv:2409.13740 â€” **PaperQA2, superhuman literature synthesis**
- FutureHouse Robin: https://github.com/Future-House/robin â€” **End-to-end multi-agent discovery, made real discovery (ripasudil for dAMD)**
- FutureHouse Platform: https://www.futurehouse.org/

#### Deep Research
- [ ] Weidener, L. et al. (2026). "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery." arXiv:2601.12542 â€” **SOTA on BixBench, minutes vs hours turnaround**

### ðŸ“š Survey Papers (Must Read)

- [ ] **"Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents."** arXiv:2503.24047 (Mar 2025). 34 pages, comprehensive roadmap.
- [ ] **"Agentic AI for Scientific Discovery: A Survey of Progress, Challenges, and Future Directions."** arXiv:2503.08979 (Mar 2025). Categorizes systems across chemistry, biology, materials science.
- [ ] **"Collective Intelligence: On the Promise and Reality of Multi-Agent Systems for AI-Driven Scientific Discovery."** Preprints.org 202508.1640 (Aug 2025). **Directly relevant** â€” maps research workflow to MAS potential.

---

## Theoretical Foundations

### Multi-Agent Debate & Deliberation
- [x] Du, Y. et al. (2023). "Improving Factuality and Reasoning in Language Models through Multiagent Debate." ICML 2024. arXiv:2305.14325 â€” **Foundational paper, "society of minds"**
- [ ] Liang, T. et al. (2023). "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"
- [ ] Chan, C. et al. (2023). "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"
- [ ] Li, Y. et al. (2024). "Improving Multi-Agent Debate with Sparse Communication Topology." EMNLP 2024. â€” **41% token reduction while preserving accuracy**
- [ ] "Can LLM Agents Really Debate?" arXiv:2511.07784 (Nov 2025) â€” **Process-level analysis, majority pressure effects**
- [ ] "Adaptive Heterogeneous Multi-Agent Debate for Enhanced Educational and Factual Reasoning." *J. King Saud Univ.* (Nov 2025) â€” **Heterogeneous agent ensemble with specialized roles**

### Heterogeneous LLM Ensembles
- [ ] **Awesome-LLM-Ensemble** (GitHub). https://github.com/junchenzhi/Awesome-LLM-Ensemble â€” Curated paper list
- [ ] "Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration." arXiv:2404.12715 (Apr 2024) â€” **DeePEn framework, vocabulary alignment**
- [ ] "Knowledge-Empowered, Collaborative, and Co-Evolving AI Models: The Post-LLM Roadmap." *ScienceDirect* (Dec 2024)
- [ ] "MoCo: A One-Stop Shop for Model Collaboration Research." arXiv:2601.21257 (Jan 2026)

### Multi-Agent Safety & Risks
- [x] TomaÅ¡ev, N., Franklin, M., Jacobs, J., Krier, S., & Osindero, S. (2025). *Distributional AGI Safety*. arXiv:2512.16856 â€” **Read, informs sandbox economies**
- [x] Hammond, L., Chan, A., Clifton, J., et al. (2025). *Multi-Agent Risks from Advanced AI*. arXiv:2502.14143 â€” **Read, informs emergent agency**

### Collective Intelligence (Human)
- [ ] Woolley, A. et al. (2010). "Evidence for a Collective Intelligence Factor in the Performance of Human Groups" â€” *Science*
- [ ] Malone, T. & Bernstein, M. (2015). "Handbook of Collective Intelligence" â€” MIT Press

### Science of Science
- [ ] Fortunato, S. et al. (2018). "Science of Science" â€” *Science* review paper
- [ ] Wang, D. & BarabÃ¡si, A.L. (2021). "The Science of Science" â€” Cambridge University Press

### Mixture of Experts
- [ ] Shazeer, N. et al. (2017). "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
- [ ] Fedus, W. et al. (2022). "Switch Transformers: Scaling to Trillion Parameter Models"

### Byzantine Fault Tolerance
- [x] Lamport, L., Shostak, R., & Pease, M. (1982). "The Byzantine Generals Problem." ACM TOPLAS. â€” **Classic, informs hallucination resistance**
- [ ] Castro, M. & Liskov, B. (1999). "Practical Byzantine Fault Tolerance." OSDI.

### Epistemic Networks / Philosophy
- [ ] Goldman, A. (1999). "Knowledge in a Social World" â€” epistemology of testimony
- [ ] Zollman, K. (2007). "The Communication Structure of Epistemic Communities"

### Chain-of-Thought
- [ ] Wei, J. et al. (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
- [ ] Kojima, T. et al. (2022). "Large Language Models are Zero-Shot Reasoners"

### Multiple Discovery
- [ ] Merton, R. (1961). "Singletons and Multiples in Scientific Discovery"
- [ ] Ogburn, W. & Thomas, D. (1922). "Are Inventions Inevitable?"

---

## Tools and Platforms

### Agent Infrastructure
- **clawXiv** â€” https://clawxiv.org â€” Preprint server for AI agents
- **Reviewer3** â€” Related project by Natalie Khalil
- **OpenClaw** â€” https://github.com/openclaw/openclaw â€” AI agent framework

### Formal Verification
- **Aristotle** â€” Lean theorem prover interface for AI agents
- **Mathlib** â€” Mathematics library for Lean 4
- **Lean** â€” https://leanprover.github.io/ â€” Interactive theorem prover

### Lean Formalization Projects
- Alexeev, B. (2025). "Formalization of ErdÅ‘s problems." Xena Project Blog. https://xenaproject.wordpress.com/2025/12/05/formalization-of-erdos-problems/

---

## Our Distinctive Angle

Based on literature review (2026-02-02), our project's novel contributions appear to be:

1. **Heterogeneous Model Diversity as Core Feature**: Most systems use homogeneous models. We specifically leverage different model families (Claude/GPT/Gemini/DeepSeek) for failure mode decorrelation.

2. **"Immortal Research Programs"**: Framing collective AI as cognitive institutions that persist beyond any individual agent's context window.

3. **Chain-of-Papers Analogy**: Explicit connection between external memory/papers and chain-of-thought reasoning at collective scale.

4. **Byzantine Fault Tolerance for Hallucination**: Adapting distributed systems theory specifically for collective verification.

5. **Empirical Grounding in ErdÅ‘s Data**: Unique dataset showing heterogeneous collaboration patterns in mathematical discovery.

---

## Reading Status Legend

- [x] Read and incorporated
- [ ] On reading list
- **Bold note** â€” Key insight from source

---

*Last updated: 2026-02-02*
